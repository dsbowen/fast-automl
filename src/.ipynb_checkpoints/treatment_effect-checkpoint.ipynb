{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T23:22:32.016196Z",
     "start_time": "2021-01-05T23:22:30.449458Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocess import Preprocessor\n",
    "\n",
    "import ml_inference\n",
    "from ml_inference import (\n",
    "    BaselineRegressor, AutoRegressor, cross_val_plot, error_plot\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "INFILE = '../data/pennycook_et_al_study2_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:39:06.308688Z",
     "start_time": "2021-01-06T14:39:06.225635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SharingType_1</th>\n",
       "      <th>SharingType_2</th>\n",
       "      <th>SharingType_3</th>\n",
       "      <th>SharingType_4</th>\n",
       "      <th>SharingType_6</th>\n",
       "      <th>SharingType_5</th>\n",
       "      <th>SocialMedia_1</th>\n",
       "      <th>SocialMedia_2</th>\n",
       "      <th>SocialMedia_3</th>\n",
       "      <th>SocialMedia_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>English</th>\n",
       "      <th>Partisan</th>\n",
       "      <th>Social_Conserv</th>\n",
       "      <th>Economic_Conserv</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Party</th>\n",
       "      <th>POTUS2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SharingType_1  SharingType_2  SharingType_3  SharingType_4  SharingType_6  \\\n",
       "0            1.0            1.0            1.0            1.0            0.0   \n",
       "1            1.0            0.0            1.0            0.0            0.0   \n",
       "2            0.0            1.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            1.0            1.0            1.0            0.0            0.0   \n",
       "\n",
       "   SharingType_5  SocialMedia_1  SocialMedia_2  SocialMedia_3  SocialMedia_4  \\\n",
       "0            1.0            1.0            1.0            1.0            1.0   \n",
       "1            0.0            1.0            1.0            0.0            0.0   \n",
       "2            0.0            1.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            1.0            1.0            1.0            1.0            1.0   \n",
       "\n",
       "   ...  Education  Income  English  Partisan  Social_Conserv  \\\n",
       "0  ...       17.0     9.0      1.0       3.0             1.0   \n",
       "1  ...       19.0     3.0      1.0       5.0             4.0   \n",
       "2  ...       16.0     7.0      1.0       3.0             2.0   \n",
       "3  ...       13.0     4.0      1.0       2.0             4.0   \n",
       "4  ...       14.0     6.0      1.0       1.0             5.0   \n",
       "\n",
       "   Economic_Conserv  Treatment      Diff        Party  POTUS2016  \n",
       "0               2.0        1.0 -0.200000     Democrat    Clinton  \n",
       "1               4.0        0.0 -0.666667   Republican      Trump  \n",
       "2               2.0        0.0  0.000000  Independent    Clinton  \n",
       "3               4.0        0.0  0.000000     Democrat    Clinton  \n",
       "4               5.0        0.0  0.200000     Democrat    Clinton  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INFILE)\n",
    "X, treat, y = df.drop(columns='Diff'), df.Treatment, df.Diff\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T23:22:36.639243Z",
     "start_time": "2021-01-05T23:22:36.631261Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class BaselineTreatmentRegressor(LinearRegression):\n",
    "    def __init__(self, treatment_var):\n",
    "        self.treatment_var = treatment_var\n",
    "        super().__init__()\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return super().fit(self.transform_X(X), y, sample_weight)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return super().predict(self.transform_X(X))\n",
    "    \n",
    "    def transform_X(self, X):\n",
    "        return (\n",
    "            X[self.treatment_var].values if isinstance(X, pd.DataFrame)\n",
    "            else X[:, self.treatment_var]\n",
    "        ).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T23:22:37.411733Z",
     "start_time": "2021-01-05T23:22:37.408111Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_treatment_idx(treatment_var, X):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "         X = pd.DataFrame(X)\n",
    "    return pd.get_dummies(X[treatment_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:57:13.070150Z",
     "start_time": "2021-01-06T14:57:13.024474Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class TreatmentRegressor():\n",
    "    def __init__(self, models, treatment_var, scoring=r2_score):\n",
    "        self.models = models\n",
    "        self.treatment_arms = list(models.keys())\n",
    "        self.treatment_var = treatment_var\n",
    "        self.scoring = scoring\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        def fit_weights(X, y):\n",
    "            X_t = self.transform_X(X)\n",
    "            self.constrained_weight_ = fit_constrained_weight(X_t, y)\n",
    "            resid = y - (X_t * self.constrained_weight_).sum(axis=1)\n",
    "            split = treatment_split(self.treatment_var, X, [X_t, resid])\n",
    "            self.weight_ = pd.DataFrame(\n",
    "                {key: fit_unconstrained_weight(X, resid) \n",
    "                for key, (_, X, resid) in split.items()}\n",
    "            )[self.treatment_arms]\n",
    "            \n",
    "        def fit_constrained_weight(X, y):\n",
    "            # constrain weights to sum to 1\n",
    "            reference = X.columns[0]\n",
    "            y -= X[reference]\n",
    "            X = X.apply(lambda x: x-X[reference]).drop(columns=reference)\n",
    "            reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "            return pd.Series(\n",
    "                index=self.treatment_arms,\n",
    "                data=np.insert(reg.coef_, 0, 1-reg.coef_.sum())\n",
    "            )\n",
    "        \n",
    "        def fit_unconstrained_weight(X, y):\n",
    "            # residual weights sum to 0\n",
    "            # INCREASE THE WEIGHT UNTIL ALL COEFS ARE BETWEEN 0 AND 1\n",
    "            # make this the lower bound\n",
    "            reg = Ridge(500, fit_intercept=False).fit(X, y)\n",
    "            return (reg.coef_ - reg.coef_.mean()) + self.constrained_weight_\n",
    "\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True)\n",
    "        # store means and stds for each treatment arm\n",
    "        self.mean_ = y.groupby(X[self.treatment_var]).mean()\n",
    "        self.std_ = y.groupby(X[self.treatment_var]).std()\n",
    "        # standardize y for each condition\n",
    "        treatment_idx = self.get_treatment_idx(X)\n",
    "        y = (y - treatment_idx @ self.mean_) / (treatment_idx @ self.std_)\n",
    "        # train models for each treatment arm\n",
    "        split = treatment_split(self.treatment_var, X, y)\n",
    "        [self.models[key].fit(X, y) for key, (X, y) in split.items()]\n",
    "        # fit weights\n",
    "        fit_weights(X, y)\n",
    "        return self\n",
    "    \n",
    "    def get_treatment_idx(self, X):\n",
    "        idx = get_treatment_idx(self.treatment_var, X)\n",
    "        return idx[self.treatment_arms].reset_index(drop=True)\n",
    "\n",
    "    def predict(self, X, constrained=False):\n",
    "        treatment_idx = self.get_treatment_idx(X)\n",
    "        X = self.transform_X(X)\n",
    "        if constrained:\n",
    "            y_pred = (self.constrained_weight_ * X).sum(axis=1)\n",
    "        else:\n",
    "            y_pred = ((treatment_idx @ self.weight_.T) * X).sum(axis=1)\n",
    "        return y_pred * (treatment_idx @ self.std_) + treatment_idx @ self.mean_\n",
    "    \n",
    "    def predict_effect(self, X, control_val=0, treatment_val=1):\n",
    "        def unnormalize(df, value):\n",
    "            df[value] = df[value] * self.std_[value] + self.mean_[value]\n",
    "            \n",
    "        X = self.transform_X(X)\n",
    "        y_pred = X @ self.weight_[[control_val, treatment_val]]\n",
    "        unnormalize(y_pred, control_val)\n",
    "        unnormalize(y_pred, treatment_val)\n",
    "        return y_pred[treatment_val] - y_pred[control_val]\n",
    "        \n",
    "    def transform_X(self, X):\n",
    "        X = (\n",
    "            X.drop(columns=self.treatment_var) if isinstance(X, pd.DataFrame) \n",
    "            else np.delete(X, self.treatment_var, axis=1)\n",
    "        )\n",
    "        return pd.DataFrame({\n",
    "            key: model.predict(X) for key, model in self.models.items()\n",
    "        }).reset_index()[self.treatment_arms]\n",
    "    \n",
    "    def score(self, X, y, constrained=False, *args, **kwargs):\n",
    "        return self.scoring(y, self.predict(X, constrained), *args, **kwargs)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        params = dict(\n",
    "            models=self.models,\n",
    "            treatment_var=self.treatment_var,\n",
    "            scoring=self.scoring\n",
    "        )\n",
    "#         if deep:\n",
    "#             control_params = self.control_model.get_params(deep)\n",
    "#             treat_params = self.treat_model.get_params(deep)\n",
    "#             params.update({'control__'+key: val for key, val in control_params.items()})\n",
    "#             params.update({'treat__'+key: val for key, val in treat_params.items()})\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.models = params['models']\n",
    "        self.treatment_var = params['treatment_var']\n",
    "        self.scorer = params['scorer']\n",
    "\n",
    "def explain_effect(reg, X, nsamples=1000, local=True, scoring=r2_score, scoring_params={}):\n",
    "    if local:\n",
    "        g = lambda effect_pred: effect_pred\n",
    "    else:\n",
    "        effect = reg.predict_effect(X)\n",
    "        g = lambda effect_pred: scoring(effect, effect_pred, **scoring_params)\n",
    "    explainer = gshap.KernelExplainer(reg.predict_effect, X, g)\n",
    "    gshap_values = explainer.gshap_values(X, nsamples=nsamples)\n",
    "    if local:\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.DataFrame(columns=X.columns, data=gshap_values.T)\n",
    "        return gshap_values.T\n",
    "    gshap_values /= gshap_values.sum()\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return pd.DataFrame({'Feature': X.columns, 'G-SHAP': gshap_values})\n",
    "    return gshap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T23:22:38.127632Z",
     "start_time": "2021-01-05T23:22:38.121084Z"
    }
   },
   "outputs": [],
   "source": [
    "def treatment_split(treatment_var, X, vectors=[], rm_treatment=True):\n",
    "    def split_vectors(idx):\n",
    "        if not vectors:\n",
    "            return split_vector(X, idx)\n",
    "        return [split_vector(v, idx) for v in [X]+vectors]\n",
    "    \n",
    "    def split_vector(v, idx):\n",
    "        return (\n",
    "            v[idx==1].reset_index(drop=True) if isinstance(v, (pd.DataFrame, pd.Series))\n",
    "            else v[idx]\n",
    "        )\n",
    "    \n",
    "    if not isinstance(vectors, list):\n",
    "        vectors = [vectors]\n",
    "    treatment_idx = get_treatment_idx(treatment_var, X)\n",
    "    if rm_treatment:\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            # treat_var is a column name\n",
    "            X = X.drop(columns=treatment_var)\n",
    "        else:\n",
    "            # treat_var is a column index\n",
    "            X = np.delete(X, treatment_var, axis=1)\n",
    "    return {key: split_vectors(idx) for key, idx in treatment_idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T23:52:37.574636Z",
     "start_time": "2021-01-05T23:23:01.928893Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning model for treatment arm 0.0\n",
      "\n",
      "Running tuner 1 of 9\n",
      "Best estimator score: 0.0407\n",
      "\n",
      "Running tuner 2 of 9\n",
      "Best estimator score: -0.0121\n",
      "\n",
      "Running tuner 3 of 9\n",
      "Best estimator score: 0.0889\n",
      "\n",
      "Running tuner 4 of 9\n",
      "Best estimator score: 0.0793\n",
      "\n",
      "Running tuner 5 of 9\n",
      "Best estimator score: 0.0938\n",
      "\n",
      "Running tuner 6 of 9\n",
      "Best estimator score: 0.0727\n",
      "\n",
      "Running tuner 7 of 9\n",
      "Best estimator score: 0.0917\n",
      "\n",
      "Running tuner 8 of 9\n",
      "Best estimator score: 0.0895\n",
      "\n",
      "Running tuner 9 of 9\n",
      "Best estimator score: 0.0565\n",
      "\n",
      "Adding estimator 1\n",
      "Best ensemble score: 0.0938\n",
      "\n",
      "Adding estimator 2\n",
      "Best ensemble score: 0.1188\n",
      "\n",
      "Adding estimator 3\n",
      "Best ensemble score: 0.1264\n",
      "\n",
      "Adding estimator 4\n",
      "Best ensemble score: 0.1326\n",
      "\n",
      "Adding estimator 5\n",
      "Best ensemble score: 0.1337\n",
      "\n",
      "Adding estimator 6\n",
      "Best ensemble score: 0.1371\n",
      "\n",
      "Adding estimator 7\n",
      "Best ensemble score: 0.1371\n",
      "\n",
      "Tuning model for treatment arm 1.0\n",
      "\n",
      "Running tuner 1 of 9\n",
      "Best estimator score: 0.0777\n",
      "\n",
      "Running tuner 2 of 9\n",
      "Best estimator score: -0.0393\n",
      "\n",
      "Running tuner 3 of 9\n",
      "Best estimator score: 0.0552\n",
      "\n",
      "Running tuner 4 of 9\n",
      "Best estimator score: -0.1021\n",
      "\n",
      "Running tuner 5 of 9\n",
      "Best estimator score: 0.0640\n",
      "\n",
      "Running tuner 6 of 9\n",
      "Best estimator score: 0.0730\n",
      "\n",
      "Running tuner 7 of 9\n",
      "Best estimator score: 0.0617\n",
      "\n",
      "Running tuner 8 of 9\n",
      "Best estimator score: 0.0530\n",
      "\n",
      "Running tuner 9 of 9\n"
     ]
    }
   ],
   "source": [
    "def train_autoreg(treatment, X, y):\n",
    "    print('\\nTuning model for treatment arm', treatment)\n",
    "    return AutoRegressor(preprocess=Preprocessor(X), n_jobs=-1).tune(X, y, n_iter=2**5)\n",
    "\n",
    "split = treatment_split('Treatment', X, y)\n",
    "models = {key: train_autoreg(key, X, y) for key, (X, y) in split.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:57:25.255006Z",
     "start_time": "2021-01-06T14:57:18.709388Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = TreatmentRegressor(models, 'Treatment')\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TreatmentRegressor at 0x7f5b22042af0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def make_svr_pipeline():\n",
    "    return make_pipeline(\n",
    "        Preprocessor(X),\n",
    "        SVR()\n",
    "    )\n",
    "\n",
    "models = {\n",
    "    0: make_svr_pipeline(),\n",
    "    1: make_svr_pipeline()\n",
    "}\n",
    "reg = TreatmentRegressor(models, 'Treatment')\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:58:55.807004Z",
     "start_time": "2021-01-06T14:58:54.982203Z"
    }
   },
   "outputs": [],
   "source": [
    "effect = reg.predict_effect(X)\n",
    "sns.histplot(effect, kde=True)\n",
    "effect.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:01:15.625011Z",
     "start_time": "2021-01-06T15:01:15.278872Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_df = reg.weight_.copy()\n",
    "weight_df = weight_df.apply(lambda x: x-reg.constrained_weight_)\n",
    "ax = sns.heatmap(weight_df, center=0, annot=True)\n",
    "ax.set(xlabel='Treatment group', ylabel='Weight on treatment-specific model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:07:07.858465Z",
     "start_time": "2021-01-06T14:02:24.345158Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    score = {'C': [], 'UC': []}\n",
    "    kf = KFold(10, shuffle=True)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        reg.fit(X_train, y_train)\n",
    "        score['UC'].append(reg.score(X_test, y_test, constrained=False))\n",
    "        score['C'].append(reg.score(X_test, y_test, constrained=True))\n",
    "    score = {key: np.array(val).mean() for key, val in score.items()}\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(scores)\n",
    "tmp_df['Diff'] = tmp_df['UC'] - tmp_df['C']\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_1samp(tmp_df['Diff'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def moderation_test(reg, X, y, repeat=10, cv=10):\n",
    "    def compute_scores(kf, reg, X, y):\n",
    "        score = {'Unconstrained': [], 'Constrained': []}\n",
    "        # compute score for all folds\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            reg = delayed(reg.fit)(X_train, y_train)\n",
    "            score['Unconstrained'].append(\n",
    "                delayed(reg.score)(X_test, y_test, constrained=False)\n",
    "            )\n",
    "            score['Constrained'].append(\n",
    "                delayed(reg.score)(X_test, y_test, constrained=True)\n",
    "            )\n",
    "        # return mean CV score\n",
    "        return delayed(dict)(\n",
    "            Unconstrained=np.array(score['Unconstrained']).mean(), \n",
    "            Constrained=np.array(score['Constrained']).mean()\n",
    "        ).compute()\n",
    "        \n",
    "    scores = []\n",
    "    for _ in range(repeat):\n",
    "        kf = KFold(cv, shuffle=True)\n",
    "        scores.append(compute_scores(kf, reg, X, y))\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores['Delta'] = scores['Unconstrained'] - scores['Constrained']\n",
    "    res = ttest_1samp(df['Diff'], 0)\n",
    "    # convert p-value for 1-tailed hypothesis\n",
    "    pvalue = res.pvalue/2 if res.statistic > 0 else (1-res.pvalue/2)\n",
    "    return scores, res.statistic, pvalue\n",
    "\n",
    "scores, t, p = moderation_test(reg, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "\n",
    "def moderation_test(reg, X, y, repeat=10, cv=10):\n",
    "    def compute_scores(kf, reg, X, y):\n",
    "        reg = clone(reg)\n",
    "        X, y = X.copy(), y.copy()\n",
    "        score = {'Unconstrained': [], 'Constrained': []}\n",
    "        # compute score for all folds\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            reg = delayed(reg.fit)(X_train, y_train)\n",
    "            score['Unconstrained'].append(\n",
    "                delayed(reg.score)(X_test, y_test, constrained=False)\n",
    "            )\n",
    "            score['Constrained'].append(\n",
    "                delayed(reg.score)(X_test, y_test, constrained=True)\n",
    "            )\n",
    "        # return mean CV score\n",
    "        return dict(\n",
    "            Unconstrained=np.array(score['Unconstrained']).mean(), \n",
    "            Constrained=np.array(score['Constrained']).mean()\n",
    "        )\n",
    "        \n",
    "    scores = []\n",
    "    for _ in range(repeat):\n",
    "        kf = KFold(cv, shuffle=True)\n",
    "        scores.append(compute_scores(kf, reg, X, y))\n",
    "    scores = delayed(pd.DataFrame)(scores).compute()\n",
    "    scores['Delta'] = scores['Unconstrained'] - scores['Constrained']\n",
    "    res = ttest_1samp(df['Diff'], 0)\n",
    "    # convert p-value for 1-tailed hypothesis\n",
    "    pvalue = res.pvalue/2 if res.statistic > 0 else (1-res.pvalue/2)\n",
    "    return scores, res.statistic, pvalue\n",
    "\n",
    "scores, t, p = moderation_test(reg, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T14:31:02.813544Z",
     "start_time": "2021-01-06T14:31:02.790468Z"
    }
   },
   "outputs": [],
   "source": [
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-inference",
   "language": "python",
   "name": "ml-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
