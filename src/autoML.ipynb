{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:41:24.705711Z",
     "start_time": "2020-12-21T18:41:23.363769Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocess import Preprocessor\n",
    "\n",
    "from ml_inference import BaselineRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "INFILE = '../data/pennycook_et_al_study2_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:41:24.880833Z",
     "start_time": "2020-12-21T18:41:24.769802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SharingType_1</th>\n",
       "      <th>SharingType_2</th>\n",
       "      <th>SharingType_3</th>\n",
       "      <th>SharingType_4</th>\n",
       "      <th>SharingType_6</th>\n",
       "      <th>SharingType_5</th>\n",
       "      <th>SocialMedia_1</th>\n",
       "      <th>SocialMedia_2</th>\n",
       "      <th>SocialMedia_3</th>\n",
       "      <th>SocialMedia_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>English</th>\n",
       "      <th>Partisan</th>\n",
       "      <th>Social_Conserv</th>\n",
       "      <th>Economic_Conserv</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Party</th>\n",
       "      <th>POTUS2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SharingType_1  SharingType_2  SharingType_3  SharingType_4  SharingType_6  \\\n",
       "0            1.0            1.0            1.0            1.0            0.0   \n",
       "1            1.0            0.0            1.0            0.0            0.0   \n",
       "2            0.0            1.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            1.0            1.0            1.0            0.0            0.0   \n",
       "\n",
       "   SharingType_5  SocialMedia_1  SocialMedia_2  SocialMedia_3  SocialMedia_4  \\\n",
       "0            1.0            1.0            1.0            1.0            1.0   \n",
       "1            0.0            1.0            1.0            0.0            0.0   \n",
       "2            0.0            1.0            0.0            0.0            0.0   \n",
       "3            0.0            1.0            0.0            0.0            0.0   \n",
       "4            1.0            1.0            1.0            1.0            1.0   \n",
       "\n",
       "   ...  Education  Income  English  Partisan  Social_Conserv  \\\n",
       "0  ...       17.0     9.0      1.0       3.0             1.0   \n",
       "1  ...       19.0     3.0      1.0       5.0             4.0   \n",
       "2  ...       16.0     7.0      1.0       3.0             2.0   \n",
       "3  ...       13.0     4.0      1.0       2.0             4.0   \n",
       "4  ...       14.0     6.0      1.0       1.0             5.0   \n",
       "\n",
       "   Economic_Conserv  Treatment      Diff        Party  POTUS2016  \n",
       "0               2.0        1.0 -0.200000     Democrat    Clinton  \n",
       "1               4.0        0.0 -0.666667   Republican      Trump  \n",
       "2               2.0        0.0  0.000000  Independent    Clinton  \n",
       "3               4.0        0.0  0.000000     Democrat    Clinton  \n",
       "4               5.0        0.0  0.200000     Democrat    Clinton  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(INFILE)\n",
    "# df = df[df.Treatment==0]\n",
    "X, treat, y = df.drop(columns='Diff'), df.Treatment, df.Diff\n",
    "X, X_test, y, y_test = train_test_split(X, y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:41:25.406640Z",
     "start_time": "2020-12-21T18:41:25.371805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.017490228432946963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(BaselineRegressor(), X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0058821388028651445"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_reg = BaselineRegressor().fit(X, y)\n",
    "baseline_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T18:41:38.100926Z",
     "start_time": "2020-12-21T18:41:37.771631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25900279660296033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "    \n",
    "linear_reg = make_pipeline(\n",
    "    Preprocessor(),\n",
    "    LinearRegression()\n",
    ")\n",
    "cross_val_score(linear_reg, X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25692287313206497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.fit(X, y)\n",
    "linear_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T21:29:49.777398Z",
     "start_time": "2020-12-21T21:29:49.728746Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, VotingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LassoLars, Ridge, ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import expon, uniform, poisson, randint\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "class Tuner():\n",
    "    def __init__(self, preprocess=[]):\n",
    "        self.preprocess = preprocess if isinstance(preprocess, list) else [preprocess]\n",
    "        \n",
    "    def tune(self, X, y, n_iter=10, n_jobs=None):\n",
    "        param_distributions = self.get_param_distributions(X, y)\n",
    "        est = RandomizedSearchCV(self.make_estimator(), param_distributions, n_iter=n_iter, n_jobs=n_jobs).fit(X, y)\n",
    "        self.best_score_ = est.best_score_\n",
    "        self.cv_results_ = list(zip(est.cv_results_['mean_test_score'], est.cv_results_['params']))\n",
    "        return self\n",
    "    \n",
    "    def make_best_estimator(self, q=0, return_score=False):\n",
    "        self.cv_results_.sort(key=lambda x: x[0], reverse=True)\n",
    "        idx = round(q*(len(self.cv_results_)-1))\n",
    "        est = self.make_estimator(**self.cv_results_[idx][1])\n",
    "        return (self.cv_results_[idx][0], est) if return_score else est\n",
    "    \n",
    "    def rm_params(self, q=0):\n",
    "        idx = round(q*(len(self.best_params_)-1))\n",
    "        return self.best_params_.pop(idx)\n",
    "\n",
    "\n",
    "class RandomForestRegressorTuner(Tuner):    \n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            RandomForestRegressor()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'randomforestregressor__n_estimators': poisson(1, 2**5)\n",
    "        }\n",
    "    \n",
    "    \n",
    "class LassoLarsTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            LassoLars(normalize=True)\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'lassolars__alpha': expon(0, 1)\n",
    "        }\n",
    "    \n",
    "    \n",
    "class RidgeTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            Ridge(normalize=True)\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'ridge__alpha': expon(0, 1)\n",
    "        }\n",
    "    \n",
    "    \n",
    "class ElasticNetTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            ElasticNet(normalize=True)\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "    \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'elasticnet__alpha': expon(0, 1),\n",
    "            'elasticnet__l1_ratio': uniform(0, 1)\n",
    "        }\n",
    "    \n",
    "    \n",
    "class KernelRidgeTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            StandardScaler(),\n",
    "            KernelRidge()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "    \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'kernelridge__alpha': expon(0, 1),\n",
    "            'kernelridge__degree': list(range(2, 5)),\n",
    "            'kernelridge__kernel': ['linear', 'poly', 'rbf', 'laplacian']\n",
    "        }\n",
    "    \n",
    "    \n",
    "class SVRTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            StandardScaler(),\n",
    "            SVR()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'svr__C': expon(0, 1),\n",
    "            'svr__degree': list(range(2, 5)),\n",
    "            'svr__kernel': ['linear', 'poly', 'rbf'],\n",
    "        }\n",
    "    \n",
    "class KNeighborsRegressorTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            StandardScaler(),\n",
    "            KNeighborsRegressor()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'kneighborsregressor__n_neighbors': randint(1, .05*X.shape[0]),\n",
    "            'kneighborsregressor__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    \n",
    "    \n",
    "class AdaBoostRegressorTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            AdaBoostRegressor()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "        \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'adaboostregressor__n_estimators': poisson(1, 2**5)\n",
    "        }\n",
    "    \n",
    "class XGBRegressorTuner(Tuner):\n",
    "    def make_estimator(self, **params):\n",
    "        est = make_pipeline(\n",
    "            *self.preprocess,\n",
    "            PolynomialFeatures(),\n",
    "            PCA(),\n",
    "            XGBRegressor()\n",
    "        )\n",
    "        return est.set_params(**params)\n",
    "    \n",
    "    def get_param_distributions(self, X, y):\n",
    "        return {\n",
    "            'polynomialfeatures__degree': [1, 2],\n",
    "            'pca__n_components': list(range(1, X.shape[1])),\n",
    "            'xgbregressor__gamma': expon(0, 1),\n",
    "            'xgbregressor__max_depth': list(range(10)),\n",
    "            'xgbregressor__min_child_weight': expon(0, 1),\n",
    "            'xgbregressor__max_delta_step': expon(0, 1),\n",
    "            'xgbregressor__lambda': expon(0, 1),\n",
    "            'xgbregressor__alpha': expon(0, 1),\n",
    "        }\n",
    "    \n",
    "# tuner = XGBRegressorTuner(preprocess=Encoder())\n",
    "# tuner.make_estimator().get_params()\n",
    "# tuner.tune(X, y, n_iter=2)\n",
    "# tuner.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tuner 1 of 7\n",
      "Running tuner 2 of 7\n",
      "Running tuner 3 of 7\n",
      "Running tuner 4 of 7\n",
      "Running tuner 5 of 7\n",
      "Running tuner 6 of 7\n",
      "Running tuner 7 of 7\n",
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tuners = [\n",
    "    AdaBoostRegressorTuner(preprocess=Preprocessor()),\n",
    "    KernelRidgeTuner(preprocess=Preprocessor()),\n",
    "    RidgeTuner(preprocess=Preprocessor()),\n",
    "    SVRTuner(preprocess=Preprocessor()),\n",
    "    RandomForestRegressorTuner(preprocess=Preprocessor()),\n",
    "    XGBRegressorTuner(preprocess=Preprocessor()),\n",
    "    KNeighborsRegressorTuner(preprocess=Preprocessor()),\n",
    "]\n",
    "for i, tuner in enumerate(tuners):\n",
    "    print('Running tuner {} of {}'.format(i+1, len(tuners)))\n",
    "    tuner.tune(X, y, n_iter=2**4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class ConstrainedLinearRegression(LinearRegression):\n",
    "    def __init__(self, constraint=0, normalize=False, copy_X=True, n_jobs=None):\n",
    "        self.constraint = constraint\n",
    "        super().__init__(fit_intercept=False, normalize=normalize, copy_X=copy_X, n_jobs=n_jobs)\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        if X.shape[1] == 1:\n",
    "            self.coef_ = np.array([1])\n",
    "            return self\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        X_0, X_rest = X[:,0], X[:,1:]\n",
    "        X_rest = (X_rest.T - X_0).T\n",
    "        y = y - self.constraint * X_0\n",
    "        super().fit(X_rest, y, sample_weight)\n",
    "        self.coef_ = np.insert(self.coef_, 0, self.constraint - self.coef_.sum())\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.base import clone, is_classifier\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
    "from sklearn.ensemble._base import _fit_single_estimator\n",
    "from sklearn.model_selection import check_cv, cross_val_predict\n",
    "from sklearn.utils.fixes import delayed\n",
    "\n",
    "def _predict_single_estimator(estimator, X):\n",
    "    return estimator.predict(X)\n",
    "\n",
    "\n",
    "class _EnsembleBase(StackingRegressor):\n",
    "    def __init__(self, estimators, cv=None, n_jobs=None, verbose=0):\n",
    "        super().__init__(estimators, cv=cv, n_jobs=n_jobs, verbose=verbose)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        predictions = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_predict_single_estimator)(est, X)\n",
    "            for est in self.estimators_\n",
    "        )\n",
    "        return self._concatenate_predictions(X, predictions)\n",
    "    \n",
    "    def _fit_estimators(self, X, y, estimators, sample_weight):\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_single_estimator)(clone(est), X, y, sample_weight)\n",
    "            for est in estimators\n",
    "        )\n",
    "        \n",
    "    def _check_cv(self):\n",
    "        cv = check_cv(self.cv, y=y, classifier=is_classifier(self))\n",
    "        if hasattr(cv, 'random_state') and cv.random_state is None:\n",
    "            cv.random_state = np.random.RandomState()\n",
    "        if hasattr(cv, 'shuffle'):\n",
    "            cv.shuffle = True\n",
    "        cv.shuffle = True\n",
    "        return cv\n",
    "    \n",
    "    def _cross_val_predict(self, X, y, estimators, cv, sample_weight):\n",
    "        fit_params = (\n",
    "            {} if sample_weight is None else {'sample_weight': sample_weight}\n",
    "        )\n",
    "        predictions = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(cross_val_predict)(\n",
    "                clone(est), X, y, \n",
    "                cv=deepcopy(cv), \n",
    "                n_jobs=self.n_jobs, \n",
    "                fit_params=fit_params, \n",
    "                verbose=self.verbose\n",
    "            )\n",
    "            for est in estimators\n",
    "        )\n",
    "        return self._concatenate_predictions(X, predictions)\n",
    "    \n",
    "\n",
    "class StackingRegressorRFECV(_EnsembleBase):   \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        def get_rfe_scores(X_meta, estimators):\n",
    "            rfe_progress = []\n",
    "            while estimators:\n",
    "                score = cross_val_score(linear_reg, X_meta, y, cv=cv).mean()\n",
    "                linear_reg.fit(X_meta, y)\n",
    "                rfe_progress.append((score, estimators.copy(), linear_reg.coef_))\n",
    "                drop_idx = int(np.argmin(linear_reg.coef_))\n",
    "                estimators.pop(drop_idx)\n",
    "                X_meta = np.delete(X_meta, drop_idx, axis=1)\n",
    "            return max(rfe_progress, key=lambda x: x[0])\n",
    "        \n",
    "        names, all_estimators = self._validate_estimators()\n",
    "        cv = self._check_cv()\n",
    "        X_meta = self._cross_val_predict(X, y, all_estimators, cv, sample_weight)\n",
    "        linear_reg = ConstrainedLinearRegression(1)\n",
    "        estimators = list(zip(names, all_estimators))\n",
    "        self.best_score_, estimators, linear_reg.coef_ = get_rfe_scores(X_meta, estimators)\n",
    "        self.names_, estimators = zip(*estimators)\n",
    "        self._fit_estimators(X, y, estimators, sample_weight)\n",
    "        self.final_estimator_ = linear_reg\n",
    "        return self\n",
    "    \n",
    "    def make_best_estimator(self):\n",
    "        estimators = list(zip(self.names_, self.estimators_))\n",
    "        return VotingRegressor(\n",
    "            estimators, weights=self.final_estimator_.coef_, \n",
    "            n_jobs=self.n_jobs, verbose=self.verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingStepwiseRegressorCV(_EnsembleBase):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        def get_stepwise_scores(X_meta, estimators):\n",
    "            best_score = -np.inf\n",
    "            in_estimators, X_in = [], None\n",
    "            out_estimators, X_out = estimators.copy(), X_meta\n",
    "            while out_estimators:\n",
    "                new_scores = []\n",
    "                for col in X_out.T:\n",
    "                    col = col.reshape(-1, 1)\n",
    "                    X = col if X_in is None else np.concatenate((X_in, col), axis=1)\n",
    "                    coef_ = linear_reg.fit(X, y).coef_\n",
    "                    if any(coef_ < 0):\n",
    "                        # make sure estimators get non-negative weight\n",
    "                        # otherwise, the ensemble has probably overfit\n",
    "                        new_scores.append(-np.inf)\n",
    "                    else:\n",
    "                        new_scores.append(cross_val_score(linear_reg, X, y, cv=cv).mean())\n",
    "                idx = np.argmax(new_scores)\n",
    "                if new_scores[idx] <= best_score:\n",
    "                    break\n",
    "                best_score = new_scores[idx]\n",
    "                col = X_out[:, idx].reshape(-1, 1)\n",
    "                X_in = col if X_in is None else np.concatenate((X_in, col), axis=1)\n",
    "                X_out = np.delete(X_out, idx, axis=1)\n",
    "                in_estimators.append(out_estimators.pop(idx))\n",
    "            return best_score, in_estimators, linear_reg.fit(X_in, y).coef_\n",
    "            \n",
    "        names, all_estimators = self._validate_estimators()\n",
    "        cv = self._check_cv()\n",
    "        X_meta = self._cross_val_predict(X, y, all_estimators, cv, sample_weight)\n",
    "        linear_reg = ConstrainedLinearRegression(1)\n",
    "        estimators = list(zip(names, all_estimators))\n",
    "        self.best_score_, estimators, linear_reg.coef_ = get_stepwise_scores(X_meta, estimators)\n",
    "        self.names_, estimators = zip(*estimators)\n",
    "        self._fit_estimators(X, y, estimators, sample_weight)\n",
    "        self.final_estimator_ = linear_reg\n",
    "        return self\n",
    "    \n",
    "    def make_best_estimator(self):\n",
    "        estimators = list(zip(self.names_, self.estimators_))\n",
    "        return VotingRegressor(\n",
    "            estimators, weights=self.final_estimator_.coef_, \n",
    "            n_jobs=self.n_jobs, verbose=self.verbose\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05861217266966494"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators = [tuner.make_best_estimator() for tuner in tuners]\n",
    "estimators = [('estimator {}'.format(i), est) for i, est in enumerate(estimators)]\n",
    "reg = StackingStepwiseRegressorCV(estimators)\n",
    "reg.fit(X, y)\n",
    "reg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23717454, 0.40588064, 0.35694482])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T22:22:18.128968Z",
     "start_time": "2020-12-21T22:00:19.411527Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_default_tuners():\n",
    "    return [\n",
    "        RandomForestRegressorTuner(),\n",
    "        LassoLarsTuner(),\n",
    "        RidgeTuner(),\n",
    "        ElasticNetTuner(),\n",
    "        KernelRidgeTuner(),\n",
    "        SVRTuner(),\n",
    "        KNeighborsRegressorTuner(),\n",
    "        AdaBoostRegressorTuner(),\n",
    "        XGBRegressorTuner()\n",
    "    ]\n",
    "\n",
    "class AutoRegressor():\n",
    "    def __init__(self, tuners=[], preprocessors=[], max_ensemble_size=100, n_ensembles=5, n_iter=10, n_jobs=None, verbose=False, cv=None):\n",
    "        self.tuners = tuners or make_default_tuners()\n",
    "        self.preprocessors = preprocessors if isinstance(preprocessors, list) else [preprocessors]\n",
    "        self.max_ensemble_size = max_ensemble_size\n",
    "        self.n_ensembles = n_ensembles\n",
    "        self.n_iter = n_iter\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "        self.cv = cv\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        def run_tuners():\n",
    "            for i, tuner in enumerate(self.tuners):\n",
    "                print('Running tuner {} of {}'.format(i+1, len(self.tuners)))\n",
    "                tuner.tune(X, y, n_iter=self.n_iter, n_jobs=self.n_jobs)\n",
    "                print('best score', tuner.best_score_)\n",
    "                \n",
    "        for preprocessor in self.preprocessors:\n",
    "            X = preprocessor.fit_transform(X)\n",
    "        run_tuners()\n",
    "        best_params = [(res, tuner) for tuner in self.tuners for res in tuner.cv_results_]\n",
    "        # x[0][0] is the cv score\n",
    "        best_params = sorted(best_params, key=lambda x: x[0][0], reverse=True)[:self.max_ensemble_size]\n",
    "        best_estimators = [tuner.make_estimator(**params) for (_, params), tuner in best_params]\n",
    "        best_estimators = [('estimator {}'.format(i), estimator) for i, estimator in enumerate(best_estimators)]\n",
    "        voting_regressors = []\n",
    "        for i in range(self.n_ensembles):\n",
    "            print('Building ensemble {} of {}'.format(i+1, self.n_ensembles))\n",
    "            stack = StackingRegressorRFECV(best_estimators, n_jobs=self.n_jobs, cv=self.cv)\n",
    "            stack.fit(X, y)\n",
    "            print(stack.best_score_)\n",
    "            voting_regressors.append(('ensemble {}'.format(i+1), stack.make_best_estimator()))\n",
    "        self.best_estimator_ = make_pipeline(\n",
    "            *self.preprocessors,\n",
    "            VotingRegressor(voting_regressors)\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.best_estimator_.predict(X)\n",
    "    \n",
    "    def make_best_estimator(self):\n",
    "        return clone(self.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegressor():\n",
    "    def __init__(\n",
    "            self, tuners=[], preprocessors=[], ensemble_method='stepwise', max_ensemble_size=100, n_ensembles=5, n_iter=10, \n",
    "            n_jobs=None, verbose=False, cv=None\n",
    "        ):\n",
    "        self.tuners = tuners or make_default_tuners()\n",
    "        self.preprocessors = preprocessors if isinstance(preprocessors, list) else [preprocessors]\n",
    "        assert ensemble_method in ('stepwise', 'rfe')\n",
    "        self.ensemble_method = ensemble_method\n",
    "        self.max_ensemble_size = max_ensemble_size\n",
    "        self.n_ensembles = n_ensembles\n",
    "        self.n_iter = n_iter\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "        self.cv = cv\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        def run_tuners():\n",
    "            for i, tuner in enumerate(self.tuners):\n",
    "                print('Running tuner {} of {}'.format(i+1, len(self.tuners)))\n",
    "                tuner.tune(X, y, n_iter=self.n_iter, n_jobs=self.n_jobs)\n",
    "                print('best score', tuner.best_score_)\n",
    "                \n",
    "        for preprocessor in self.preprocessors:\n",
    "            X = preprocessor.fit_transform(X)\n",
    "        run_tuners()\n",
    "        best_params = [(res, tuner) for tuner in self.tuners for res in tuner.cv_results_]\n",
    "        # x[0][0] is the cv score\n",
    "        best_params = sorted(best_params, key=lambda x: x[0][0], reverse=True)[:self.max_ensemble_size]\n",
    "        best_estimators = [tuner.make_estimator(**params) for (_, params), tuner in best_params]\n",
    "        best_estimators = [('estimator {}'.format(i), estimator) for i, estimator in enumerate(best_estimators)]\n",
    "        estimators = best_estimators.pop(0)\n",
    "        linear_reg = ConstrainedLinearRegression(1)\n",
    "        score = cross_val_score(linear_reg, X, y)\n",
    "        rfe_voting_regressors = []\n",
    "        stepwise_voting_regressors = []\n",
    "        voting_regressors = []\n",
    "        for i in range(self.n_ensembles):\n",
    "            print('Building ensemble {} of {}'.format(i+1, self.n_ensembles))\n",
    "#             if self.ensemble_method == 'rfe':\n",
    "#                 stack = StackingRegressorRFECV(best_estimators, n_jobs=self.n_jobs, cv=self.cv)\n",
    "#             elif self.ensemble_method == 'stepwise':\n",
    "#                 stack = StackingStepwiseRegressorCV(best_estimators, n_jobs=self.n_jobs, cv=self.cv)\n",
    "            stack = StackingRegressorRFECV(best_estimators, n_jobs=self.n_jobs, cv=self.cv)\n",
    "            stack.fit(X, y)\n",
    "            print('RFE best score', stack.best_score_)\n",
    "            rfe_estimator = stack.make_best_estimator()\n",
    "            rfe_voting_regressors.append(('ensemble {}'.format(i+1), rfe_estimator))\n",
    "            stack = StackingStepwiseRegressorCV(best_estimators, n_jobs=self.n_jobs, cv=self.cv)\n",
    "            stack.fit(X, y)\n",
    "            print('Stepwise best score', stack.best_score_)\n",
    "            stepwise_estimator = stack.make_best_estimator()\n",
    "            stepwise_voting_regressors.append(('ensemble {}'.format(i+1), stepwise_estimator))\n",
    "            stack = StackingStepwiseRegressorCV(\n",
    "                estimators=[\n",
    "                    ('rfe_estimator', rfe_estimator),\n",
    "                    ('stepwise_estimator', stepwise_estimator)\n",
    "                ],\n",
    "                n_jobs=self.n_jobs,\n",
    "                cv=self.cv\n",
    "            )\n",
    "            stack.fit(X, y)\n",
    "            voting_regressors.append(('ensemble {}'.format(i+1), stack.make_best_estimator()))\n",
    "            print('Ensemble best score', stack.best_score_)\n",
    "        self.rfe_best_estimator_ = make_pipeline(\n",
    "            *self.preprocessors,\n",
    "            VotingRegressor(rfe_voting_regressors)\n",
    "        )\n",
    "        self.stepwise_best_estimator_ = make_pipeline(\n",
    "            *self.preprocessors,\n",
    "            VotingRegressor(stepwise_voting_regressors)\n",
    "        )\n",
    "        self.ensemble_best_estimator_ = make_pipeline(\n",
    "            *self.preprocessors,\n",
    "            VotingRegressor(voting_regressors)\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.best_estimator_.predict(X)\n",
    "    \n",
    "    def make_best_estimator(self):\n",
    "        return clone(self.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tuner 1 of 9\n",
      "best score 0.09400844635278931\n",
      "Running tuner 2 of 9\n",
      "best score -0.0026438008817306624\n",
      "Running tuner 3 of 9\n",
      "best score 0.1397755290624509\n",
      "Running tuner 4 of 9\n",
      "best score -0.0026438008817306624\n",
      "Running tuner 5 of 9\n",
      "best score 0.08409025885361458\n",
      "Running tuner 6 of 9\n",
      "best score 0.12240153875172485\n",
      "Running tuner 7 of 9\n",
      "best score 0.08687868226573803\n",
      "Running tuner 8 of 9\n",
      "best score 0.06585126758087165\n",
      "Running tuner 9 of 9\n",
      "best score 0.0273452549161598\n",
      "Building ensemble 1 of 1\n",
      "RFE best score 0.12754176389562022\n",
      "Stepwise best score 0.1316988439521851\n",
      "Ensemble best score 0.13228383570527272\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# X, y = load_diabetes(return_X_y=True)\n",
    "# X, X_test, y, y_test = train_test_split(X, y)\n",
    "X, y = df.drop(columns='Diff'), df.Diff\n",
    "X, X_test, y, y_test = train_test_split(X, y)\n",
    "autoreg = AutoRegressor(preprocessors=Preprocessor(), max_ensemble_size=3, n_iter=3, n_ensembles=1, n_jobs=-1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tuner 1 of 9\n",
      "best score 0.7353581502397176\n",
      "Running tuner 2 of 9\n",
      "best score 0.0037945080409373944\n",
      "Running tuner 3 of 9\n",
      "best score 0.6241101453034259\n",
      "Running tuner 4 of 9\n",
      "best score 0.1637886267126912\n",
      "Running tuner 5 of 9\n",
      "best score 0.7430575774937813\n",
      "Running tuner 6 of 9\n",
      "best score 0.6360758212975578\n",
      "Running tuner 7 of 9\n",
      "best score 0.7091696348974517\n",
      "Running tuner 8 of 9\n",
      "best score 0.6850572593610561\n",
      "Running tuner 9 of 9\n",
      "best score 0.6336611662968309\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.8168682666287393\n",
      "Stepwise best score 0.8028979914562203\n",
      "Ensemble best score 0.8456411446730648\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8125276916210898\n",
      "Stepwise best score 0.809429202730253\n",
      "Ensemble best score 0.8068824151601401\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8109926330434474\n",
      "Stepwise best score 0.7845336790499869\n",
      "Ensemble best score 0.8188425239722588\n",
      "\n",
      "RFE test score 0.8274430845740518\n",
      "Stepwise test score 0.7961170474563914\n",
      "Ensemble test score 0.8264556434713517\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7483340193813756\n",
      "Running tuner 2 of 9\n",
      "best score 0.5024391985230319\n",
      "Running tuner 3 of 9\n",
      "best score 0.5465255039667\n",
      "Running tuner 4 of 9\n",
      "best score 0.519840722892371\n",
      "Running tuner 5 of 9\n",
      "best score 0.6797166087042747\n",
      "Running tuner 6 of 9\n",
      "best score 0.5878344293512789\n",
      "Running tuner 7 of 9\n",
      "best score 0.6636088065987815\n",
      "Running tuner 8 of 9\n",
      "best score 0.6378800911936482\n",
      "Running tuner 9 of 9\n",
      "best score 0.7831453949295812\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.7993471765824227\n",
      "Stepwise best score 0.8111924846294676\n",
      "Ensemble best score 0.7948330043317282\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8016844276066803\n",
      "Stepwise best score 0.7952018917647112\n",
      "Ensemble best score 0.793609842738441\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8055427326799312\n",
      "Stepwise best score 0.799807094011037\n",
      "Ensemble best score 0.805840847220745\n",
      "\n",
      "RFE test score 0.8285169110509902\n",
      "Stepwise test score 0.8172928632388223\n",
      "Ensemble test score 0.8291515102017148\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7431011185086868\n",
      "Running tuner 2 of 9\n",
      "best score 0.20346663718066801\n",
      "Running tuner 3 of 9\n",
      "best score 0.5593261722723505\n",
      "Running tuner 4 of 9\n",
      "best score 0.024433364300070815\n",
      "Running tuner 5 of 9\n",
      "best score 0.8702686945171388\n",
      "Running tuner 6 of 9\n",
      "best score 0.6260114394207105\n",
      "Running tuner 7 of 9\n",
      "best score 0.7464048910247446\n",
      "Running tuner 8 of 9\n",
      "best score 0.7213902996444223\n",
      "Running tuner 9 of 9\n",
      "best score 0.7179114661202386\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.8533582293819894\n",
      "Stepwise best score 0.8169375318139002\n",
      "Ensemble best score 0.8571637208130272\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.838589285554615\n",
      "Stepwise best score 0.8240074429413442\n",
      "Ensemble best score 0.8289942760048985\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8256460006907359\n",
      "Stepwise best score 0.8334182700650027\n",
      "Ensemble best score 0.8680234118399973\n",
      "\n",
      "RFE test score 0.7598120715836976\n",
      "Stepwise test score 0.7152632475743925\n",
      "Ensemble test score 0.7635026270696887\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.727491255322245\n",
      "Running tuner 2 of 9\n",
      "best score 0.6065092125990696\n",
      "Running tuner 3 of 9\n",
      "best score 0.6471491130287064\n",
      "Running tuner 4 of 9\n",
      "best score 0.575820456612942\n",
      "Running tuner 5 of 9\n",
      "best score 0.6780153475953055\n",
      "Running tuner 6 of 9\n",
      "best score 0.4123075874249361\n",
      "Running tuner 7 of 9\n",
      "best score 0.6896715347240754\n",
      "Running tuner 8 of 9\n",
      "best score 0.6599971948592598\n",
      "Running tuner 9 of 9\n",
      "best score 0.6503100057573814\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.7893713707320889\n",
      "Stepwise best score 0.806102865810377\n",
      "Ensemble best score 0.7602291997589482\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.796241591966985\n",
      "Stepwise best score 0.7741023784537008\n",
      "Ensemble best score 0.7870682140392576\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.7957343082496512\n",
      "Stepwise best score 0.7989596229472004\n",
      "Ensemble best score 0.7863966706836398\n",
      "\n",
      "RFE test score 0.8132957559224226\n",
      "Stepwise test score 0.8147671546832063\n",
      "Ensemble test score 0.8108024200883047\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.76938427269377\n",
      "Running tuner 2 of 9\n",
      "best score 0.5064158227173869\n",
      "Running tuner 3 of 9\n",
      "best score 0.6601850480923657\n",
      "Running tuner 4 of 9\n",
      "best score 0.11442539750351119\n",
      "Running tuner 5 of 9\n",
      "best score 0.7177210917000438\n",
      "Running tuner 6 of 9\n",
      "best score 0.6214379524119558\n",
      "Running tuner 7 of 9\n",
      "best score 0.6938789399019476\n",
      "Running tuner 8 of 9\n",
      "best score 0.7092323238381141\n",
      "Running tuner 9 of 9\n",
      "best score 0.7319208804900763\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.7716126340546156\n",
      "Stepwise best score 0.7907651361412552\n",
      "Ensemble best score 0.798916447625867\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.7852995946174189\n",
      "Stepwise best score 0.7698105186033434\n",
      "Ensemble best score 0.8095503800682213\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.7680363656912783\n",
      "Stepwise best score 0.7961295689488186\n",
      "Ensemble best score 0.8090158291421645\n",
      "\n",
      "RFE test score 0.8620076294430448\n",
      "Stepwise test score 0.8047511974445432\n",
      "Ensemble test score 0.850732325555668\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7006574034524767\n",
      "Running tuner 2 of 9\n",
      "best score 0.3080185135041628\n",
      "Running tuner 3 of 9\n",
      "best score 0.5613690498058711\n",
      "Running tuner 4 of 9\n",
      "best score 0.4065626314459981\n",
      "Running tuner 5 of 9\n",
      "best score 0.7452389468281839\n",
      "Running tuner 6 of 9\n",
      "best score 0.5520060445463655\n",
      "Running tuner 7 of 9\n",
      "best score 0.7516081445566984\n",
      "Running tuner 8 of 9\n",
      "best score 0.6580910806721544\n",
      "Running tuner 9 of 9\n",
      "best score 0.6617719402385321\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.8048116600580062\n",
      "Stepwise best score 0.8506357535624772\n",
      "Ensemble best score 0.805527613479029\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8032373526562562\n",
      "Stepwise best score 0.8087985393676561\n",
      "Ensemble best score 0.8222590118251691\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8110474181618619\n",
      "Stepwise best score 0.8304507367994043\n",
      "Ensemble best score 0.8409664738060746\n",
      "\n",
      "RFE test score 0.8475668205877868\n",
      "Stepwise test score 0.8355362211324723\n",
      "Ensemble test score 0.840489851584508\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7182277137867891\n",
      "Running tuner 2 of 9\n",
      "best score 0.5747310164186912\n",
      "Running tuner 3 of 9\n",
      "best score 0.6509515648074353\n",
      "Running tuner 4 of 9\n",
      "best score 0.25218714709830714\n",
      "Running tuner 5 of 9\n",
      "best score 0.7515864673483172\n",
      "Running tuner 6 of 9\n",
      "best score 0.692494536971312\n",
      "Running tuner 7 of 9\n",
      "best score 0.7560467997650419\n",
      "Running tuner 8 of 9\n",
      "best score 0.7023633472588158\n",
      "Running tuner 9 of 9\n",
      "best score 0.720081429764989\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.8092128242301347\n",
      "Stepwise best score 0.7868387196522709\n",
      "Ensemble best score 0.813645516272161\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8257529570595399\n",
      "Stepwise best score 0.8059968344433776\n",
      "Ensemble best score 0.8022216548493988\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8120615531066484\n",
      "Stepwise best score 0.7962161344157683\n",
      "Ensemble best score 0.7978912538499227\n",
      "\n",
      "RFE test score 0.8505191428469583\n",
      "Stepwise test score 0.8139477422270187\n",
      "Ensemble test score 0.8458741490471171\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7633860784433566\n",
      "Running tuner 2 of 9\n",
      "best score 0.3513757218268852\n",
      "Running tuner 3 of 9\n",
      "best score 0.7103653241701604\n",
      "Running tuner 4 of 9\n",
      "best score -0.0061637329969259635\n",
      "Running tuner 5 of 9\n",
      "best score 0.8640481978728232\n",
      "Running tuner 6 of 9\n",
      "best score 0.5748484782463036\n",
      "Running tuner 7 of 9\n",
      "best score 0.6927375876267067\n",
      "Running tuner 8 of 9\n",
      "best score 0.7077854060392117\n",
      "Running tuner 9 of 9\n",
      "best score 0.7936124028991707\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.823620963951379\n",
      "Stepwise best score 0.7789570732405969\n",
      "Ensemble best score 0.8171931514927191\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8119629042273442\n",
      "Stepwise best score 0.8094713945935691\n",
      "Ensemble best score 0.8131079570777822\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.7952261854438937\n",
      "Stepwise best score 0.8080066664650272\n",
      "Ensemble best score 0.8281772947951763\n",
      "\n",
      "RFE test score 0.807726532785738\n",
      "Stepwise test score 0.800222555941966\n",
      "Ensemble test score 0.8071814118414085\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7361875640841535\n",
      "Running tuner 2 of 9\n",
      "best score 0.36231105120500445\n",
      "Running tuner 3 of 9\n",
      "best score 0.6970031731784895\n",
      "Running tuner 4 of 9\n",
      "best score 0.3506813667670777\n",
      "Running tuner 5 of 9\n",
      "best score 0.699385161233949\n",
      "Running tuner 6 of 9\n",
      "best score 0.5266262224192\n",
      "Running tuner 7 of 9\n",
      "best score 0.711243998022194\n",
      "Running tuner 8 of 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.675693768788288\n",
      "Running tuner 9 of 9\n",
      "best score 0.381918829606602\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.7744437503345499\n",
      "Stepwise best score 0.7570122019296291\n",
      "Ensemble best score 0.7718584383848416\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.7762016384321343\n",
      "Stepwise best score 0.7611355119523251\n",
      "Ensemble best score 0.7614614987592807\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.7568451179735727\n",
      "Stepwise best score 0.7666824846374725\n",
      "Ensemble best score 0.7750925917370808\n",
      "\n",
      "RFE test score 0.8317273620864167\n",
      "Stepwise test score 0.8341100394992138\n",
      "Ensemble test score 0.8359986557295448\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.7709599048274258\n",
      "Running tuner 2 of 9\n",
      "best score -0.011217234902483542\n",
      "Running tuner 3 of 9\n",
      "best score 0.665991014261198\n",
      "Running tuner 4 of 9\n",
      "best score 0.629887863464878\n",
      "Running tuner 5 of 9\n",
      "best score 0.6954874740397545\n",
      "Running tuner 6 of 9\n",
      "best score 0.6346977527943339\n",
      "Running tuner 7 of 9\n",
      "best score 0.7520079608933152\n",
      "Running tuner 8 of 9\n",
      "best score 0.7053252826260891\n",
      "Running tuner 9 of 9\n",
      "best score 0.638626896243722\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.8459290119695277\n",
      "Stepwise best score 0.854167355021184\n",
      "Ensemble best score 0.8458997264652783\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.8622521146637991\n",
      "Stepwise best score 0.8342915963017411\n",
      "Ensemble best score 0.8460878903133648\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.8545712524248174\n",
      "Stepwise best score 0.8166160369037708\n",
      "Ensemble best score 0.8617797367130414\n",
      "\n",
      "RFE test score 0.8173013633214046\n",
      "Stepwise test score 0.8356088415709901\n",
      "Ensemble test score 0.8246803898964523\n",
      "\n",
      "Wall time: 15min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.datasets import load_diabetes, load_boston\n",
    "\n",
    "rfe_test_score_ = []\n",
    "stepwise_test_score_ = []\n",
    "ensemble_test_score_ = []\n",
    "for i in range(10):\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "    X, X_test, y, y_test = train_test_split(X, y)\n",
    "    autoreg = AutoRegressor(max_ensemble_size=100, n_iter=2**4, n_ensembles=3, n_jobs=-1).fit(X, y)\n",
    "    reg = autoreg.rfe_best_estimator_.fit(X, y)\n",
    "    rfe_test_score_.append(reg.score(X_test, y_test))\n",
    "    print()\n",
    "    print('RFE test score', rfe_test_score_[-1])\n",
    "    reg = autoreg.stepwise_best_estimator_.fit(X, y)\n",
    "    stepwise_test_score_.append(reg.score(X_test, y_test))\n",
    "    print('Stepwise test score', stepwise_test_score_[-1])\n",
    "    reg = autoreg.ensemble_best_estimator_.fit(X, y)\n",
    "    ensemble_test_score_.append(reg.score(X_test, y_test))\n",
    "    print('Ensemble test score', ensemble_test_score_[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245916674202511 0.02708519349808612 0.7598120715836976 0.8620076294430448\n",
      "0.8067616910769017 0.033416720624429797 0.7152632475743925 0.8356088415709901\n",
      "0.8234868984485759 0.023992394974231376 0.7635026270696887 0.850732325555668\n"
     ]
    }
   ],
   "source": [
    "test_scores = [np.array(scores) for scores in (rfe_test_score_, stepwise_test_score_, ensemble_test_score_)]\n",
    "for score in test_scores:\n",
    "    print(score.mean(), score.std(), score.min(), score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tuner 1 of 9\n",
      "best score 0.12870141985581054\n",
      "Running tuner 2 of 9\n",
      "best score -0.0026147414240628385\n",
      "Running tuner 3 of 9\n",
      "best score 0.15351782549913248\n",
      "Running tuner 4 of 9\n",
      "best score 0.00031031007960604653\n",
      "Running tuner 5 of 9\n",
      "best score 0.15370653489449745\n",
      "Running tuner 6 of 9\n",
      "best score 0.13504367219993452\n",
      "Running tuner 7 of 9\n",
      "best score 0.14142730094193978\n",
      "Running tuner 8 of 9\n",
      "best score 0.13311167001058416\n",
      "Running tuner 9 of 9\n",
      "best score 0.11098018346930678\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.16608657174614433\n",
      "Stepwise best score 0.17879440809636277\n",
      "Ensemble best score 0.19151255873678094\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.19362065766121944\n",
      "Stepwise best score 0.19633730567392668\n",
      "Ensemble best score 0.17658092876254422\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.1838389333733734\n",
      "Stepwise best score 0.17775872985309535\n",
      "Ensemble best score 0.16574444485142076\n",
      "\n",
      "RFE test score 0.09660723034952334\n",
      "Stepwise test score 0.07859982499098406\n",
      "Ensemble test score 0.08725788670019274\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.11485562243122452\n",
      "Running tuner 2 of 9\n",
      "best score -0.01074185301567252\n",
      "Running tuner 3 of 9\n",
      "best score 0.13703394654885676\n",
      "Running tuner 4 of 9\n",
      "best score -0.01074185301567252\n",
      "Running tuner 5 of 9\n",
      "best score 0.13730191745823178\n",
      "Running tuner 6 of 9\n",
      "best score 0.09702585992989532\n",
      "Running tuner 7 of 9\n",
      "best score 0.11082587952779588\n",
      "Running tuner 8 of 9\n",
      "best score 0.1380151246729328\n",
      "Running tuner 9 of 9\n",
      "best score 0.08873238678238957\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.1783814133219734\n",
      "Stepwise best score 0.1842703057814512\n",
      "Ensemble best score 0.1652914272510812\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.1894998957722811\n",
      "Stepwise best score 0.16598713598177933\n",
      "Ensemble best score 0.1724589556634254\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.1942579931151955\n",
      "Stepwise best score 0.167734295513271\n",
      "Ensemble best score 0.16106037067011478\n",
      "\n",
      "RFE test score 0.14909707022873608\n",
      "Stepwise test score 0.1433806867617785\n",
      "Ensemble test score 0.1544636923438999\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.059125035562627916\n",
      "Running tuner 2 of 9\n",
      "best score -0.018748285034324352\n",
      "Running tuner 3 of 9\n",
      "best score 0.1299031696476225\n",
      "Running tuner 4 of 9\n",
      "best score 0.0007538629624578741\n",
      "Running tuner 5 of 9\n",
      "best score 0.13367418584005647\n",
      "Running tuner 6 of 9\n",
      "best score 0.12540966114097102\n",
      "Running tuner 7 of 9\n",
      "best score 0.09833681894539206\n",
      "Running tuner 8 of 9\n",
      "best score 0.09908633354652677\n",
      "Running tuner 9 of 9\n",
      "best score 0.070363276834068\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.18889181775466657\n",
      "Stepwise best score 0.18192882904737975\n",
      "Ensemble best score 0.18226612262989939\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.21438083991450116\n",
      "Stepwise best score 0.18799444439400698\n",
      "Ensemble best score 0.181572546849656\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.20415429035938085\n",
      "Stepwise best score 0.19982473946134732\n",
      "Ensemble best score 0.1838460807589659\n",
      "\n",
      "RFE test score 0.11529660801254638\n",
      "Stepwise test score 0.12208600512045065\n",
      "Ensemble test score 0.11675121720330806\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.088333301918654\n",
      "Running tuner 2 of 9\n",
      "best score 0.11146229225384419\n",
      "Running tuner 3 of 9\n",
      "best score 0.12744718143200245\n",
      "Running tuner 4 of 9\n",
      "best score 0.12097233745868878\n",
      "Running tuner 5 of 9\n",
      "best score 0.10466268062601398\n",
      "Running tuner 6 of 9\n",
      "best score 0.10863381145863582\n",
      "Running tuner 7 of 9\n",
      "best score 0.09522878807558396\n",
      "Running tuner 8 of 9\n",
      "best score 0.09176893125485816\n",
      "Running tuner 9 of 9\n",
      "best score 0.07772575317868544\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.14871761643471562\n",
      "Stepwise best score 0.15372393620039765\n",
      "Ensemble best score 0.14589095717357287\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.15660334046981522\n",
      "Stepwise best score 0.15932681502198964\n",
      "Ensemble best score 0.15669433158755613\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.15748926396721358\n",
      "Stepwise best score 0.14159874825672866\n",
      "Ensemble best score 0.15410364760980536\n",
      "\n",
      "RFE test score 0.17797587155976968\n",
      "Stepwise test score 0.17862873244091593\n",
      "Ensemble test score 0.18058963637399617\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.048653308052023544\n",
      "Running tuner 2 of 9\n",
      "best score -0.03136531857882905\n",
      "Running tuner 3 of 9\n",
      "best score 0.09008351355705128\n",
      "Running tuner 4 of 9\n",
      "best score -0.03133376768012956\n",
      "Running tuner 5 of 9\n",
      "best score 0.08846610153489454\n",
      "Running tuner 6 of 9\n",
      "best score 0.07142279939203137\n",
      "Running tuner 7 of 9\n",
      "best score 0.09637881462431949\n",
      "Running tuner 8 of 9\n",
      "best score 0.07228066513088863\n",
      "Running tuner 9 of 9\n",
      "best score 0.04600017013488933\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.14251422569410316\n",
      "Stepwise best score 0.1605215536695061\n",
      "Ensemble best score 0.13321288566205775\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.1554728663903422\n",
      "Stepwise best score 0.1383978478349378\n",
      "Ensemble best score 0.1486933346350951\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.13971289370750242\n",
      "Stepwise best score 0.16520453447230538\n",
      "Ensemble best score 0.13533856801408967\n",
      "\n",
      "RFE test score 0.1737019285530219\n",
      "Stepwise test score 0.1580603325407478\n",
      "Ensemble test score 0.16517001404265097\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.0739862679814828\n",
      "Running tuner 2 of 9\n",
      "best score -0.00830822168846499\n",
      "Running tuner 3 of 9\n",
      "best score 0.09844672295918619\n",
      "Running tuner 4 of 9\n",
      "best score -0.0004269652952809677\n",
      "Running tuner 5 of 9\n",
      "best score 0.12250697726606082\n",
      "Running tuner 6 of 9\n",
      "best score 0.12624138469125024\n",
      "Running tuner 7 of 9\n",
      "best score 0.11271444039418962\n",
      "Running tuner 8 of 9\n",
      "best score 0.09917446334244426\n",
      "Running tuner 9 of 9\n",
      "best score 0.0980408367944425\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.16231731255426707\n",
      "Stepwise best score 0.18009899838012453\n",
      "Ensemble best score 0.16422043611725157\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.17369929958300484\n",
      "Stepwise best score 0.1550083252817222\n",
      "Ensemble best score 0.1698213751734214\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.16197792308333736\n",
      "Stepwise best score 0.1605515562207071\n",
      "Ensemble best score 0.14592999782571975\n",
      "\n",
      "RFE test score 0.18240602133602302\n",
      "Stepwise test score 0.17680246918292108\n",
      "Ensemble test score 0.18961095825069962\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.03964468859854211\n",
      "Running tuner 2 of 9\n",
      "best score -0.0037111341926418183\n",
      "Running tuner 3 of 9\n",
      "best score 0.11833560094442645\n",
      "Running tuner 4 of 9\n",
      "best score -0.003697548152381991\n",
      "Running tuner 5 of 9\n",
      "best score 0.09936481736000664\n",
      "Running tuner 6 of 9\n",
      "best score 0.08750618388777684\n",
      "Running tuner 7 of 9\n",
      "best score 0.08954103968348584\n",
      "Running tuner 8 of 9\n",
      "best score 0.08657452926525241\n",
      "Running tuner 9 of 9\n",
      "best score 0.058741043661747504\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.14911457747926854\n",
      "Stepwise best score 0.1333868999067018\n",
      "Ensemble best score 0.1312201368486206\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.13064243178116425\n",
      "Stepwise best score 0.1346691597988789\n",
      "Ensemble best score 0.11586443843933307\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.1367633225279169\n",
      "Stepwise best score 0.1415159268970841\n",
      "Ensemble best score 0.09329538020222597\n",
      "\n",
      "RFE test score 0.20287743298118488\n",
      "Stepwise test score 0.1996726395700834\n",
      "Ensemble test score 0.20471490099460887\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.08095687070392758\n",
      "Running tuner 2 of 9\n",
      "best score 0.004020741776363024\n",
      "Running tuner 3 of 9\n",
      "best score 0.13607390589576826\n",
      "Running tuner 4 of 9\n",
      "best score -0.005804061145365624\n",
      "Running tuner 5 of 9\n",
      "best score 0.12416233074161154\n",
      "Running tuner 6 of 9\n",
      "best score 0.12679399740379588\n",
      "Running tuner 7 of 9\n",
      "best score 0.1086110481834353\n",
      "Running tuner 8 of 9\n",
      "best score 0.0962133462872405\n",
      "Running tuner 9 of 9\n",
      "best score 0.10138125516659838\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.17608246950646264\n",
      "Stepwise best score 0.1887322749333125\n",
      "Ensemble best score 0.16417253561395734\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.18770214761065124\n",
      "Stepwise best score 0.17677501981151872\n",
      "Ensemble best score 0.16235636076805887\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.18101666346785134\n",
      "Stepwise best score 0.1714446748872483\n",
      "Ensemble best score 0.16656728047689587\n",
      "\n",
      "RFE test score 0.12610341389523183\n",
      "Stepwise test score 0.12122224829582307\n",
      "Ensemble test score 0.12861157016276192\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.13185225434705283\n",
      "Running tuner 2 of 9\n",
      "best score -0.006237174575858262\n",
      "Running tuner 3 of 9\n",
      "best score 0.15706534728121155\n",
      "Running tuner 4 of 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.0051950490926700125\n",
      "Running tuner 5 of 9\n",
      "best score 0.1655908368069621\n",
      "Running tuner 6 of 9\n",
      "best score 0.15115760146669638\n",
      "Running tuner 7 of 9\n",
      "best score 0.12501657903563995\n",
      "Running tuner 8 of 9\n",
      "best score 0.1864837133868861\n",
      "Running tuner 9 of 9\n",
      "best score 0.10584798552688705\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.2040038598941035\n",
      "Stepwise best score 0.17469702431243145\n",
      "Ensemble best score 0.17267442365300137\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.19676020957956988\n",
      "Stepwise best score 0.1741268207630071\n",
      "Ensemble best score 0.17550341307075268\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.18083176199369128\n",
      "Stepwise best score 0.1910331417201909\n",
      "Ensemble best score 0.19381397816624793\n",
      "\n",
      "RFE test score 0.10103701721897129\n",
      "Stepwise test score 0.10425565424641425\n",
      "Ensemble test score 0.10713038490613114\n",
      "\n",
      "Running tuner 1 of 9\n",
      "best score 0.10868431343797565\n",
      "Running tuner 2 of 9\n",
      "best score -0.010926529567007081\n",
      "Running tuner 3 of 9\n",
      "best score 0.15146898605950396\n",
      "Running tuner 4 of 9\n",
      "best score -0.010880568500654598\n",
      "Running tuner 5 of 9\n",
      "best score 0.15049038646347773\n",
      "Running tuner 6 of 9\n",
      "best score 0.13727321010842453\n",
      "Running tuner 7 of 9\n",
      "best score 0.13101372889812618\n",
      "Running tuner 8 of 9\n",
      "best score 0.11257754813205043\n",
      "Running tuner 9 of 9\n",
      "best score 0.08669416894038647\n",
      "Building ensemble 1 of 3\n",
      "RFE best score 0.16942769080141315\n",
      "Stepwise best score 0.16311443564359596\n",
      "Ensemble best score 0.15796756910118842\n",
      "Building ensemble 2 of 3\n",
      "RFE best score 0.18132436953465964\n",
      "Stepwise best score 0.17339065593029693\n",
      "Ensemble best score 0.18940098780388231\n",
      "Building ensemble 3 of 3\n",
      "RFE best score 0.20078508090261563\n",
      "Stepwise best score 0.17651581820146442\n",
      "Ensemble best score 0.16765297120784065\n",
      "\n",
      "RFE test score 0.1059914204257435\n",
      "Stepwise test score 0.1408946112716899\n",
      "Ensemble test score 0.11626680236063269\n",
      "\n",
      "Wall time: 1h 36min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfe_test_score = []\n",
    "stepwise_test_score = []\n",
    "ensemble_test_score = []\n",
    "for i in range(10):\n",
    "    X, y = df.drop(columns='Diff'), df.Diff\n",
    "    X, X_test, y, y_test = train_test_split(X, y)\n",
    "    autoreg = AutoRegressor(preprocessors=Preprocessor(), max_ensemble_size=100, n_iter=2**5, n_ensembles=3, n_jobs=-1).fit(X, y)\n",
    "    reg = autoreg.rfe_best_estimator_.fit(X, y)\n",
    "    rfe_test_score.append(reg.score(X_test, y_test))\n",
    "    print()\n",
    "    print('RFE test score', rfe_test_score[-1])\n",
    "    reg = autoreg.stepwise_best_estimator_.fit(X, y)\n",
    "    stepwise_test_score.append(reg.score(X_test, y_test))\n",
    "    print('Stepwise test score', stepwise_test_score[-1])\n",
    "    reg = autoreg.ensemble_best_estimator_.fit(X, y)\n",
    "    ensemble_test_score.append(reg.score(X_test, y_test))\n",
    "    print('Ensemble test score', ensemble_test_score[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1431094014560752, 0.1423603204421809, 0.1450567063338882)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_test_score = np.array(rfe_test_score)\n",
    "stepwise_test_score = np.array(stepwise_test_score)\n",
    "ensemble_test_score = np.array(ensemble_test_score)\n",
    "rfe_test_score.mean(), stepwise_test_score.mean(), ensemble_test_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1431094014560752 0.03698229927440087 0.09660723034952334 0.20287743298118488\n",
      "0.1423603204421809 0.03522963723231343 0.07859982499098406 0.1996726395700834\n",
      "0.1450567063338882 0.03738906043423106 0.08725788670019274 0.20471490099460887\n"
     ]
    }
   ],
   "source": [
    "test_scores = [rfe_test_score, stepwise_test_score, ensemble_test_score]\n",
    "for score in test_scores:\n",
    "    print(score.mean(), score.std(), score.min(), score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010924311185860569\n",
      "-0.0029542213699329523\n"
     ]
    }
   ],
   "source": [
    "linear_reg = make_pipeline(\n",
    "    Preprocessor(),\n",
    "    LinearRegression()\n",
    ")\n",
    "linear_reg.fit(X, y)\n",
    "print(linear_reg.score(X_test, y_test))\n",
    "baseline_reg.fit(X, y)\n",
    "print(baseline_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T22:22:27.613099Z",
     "start_time": "2020-12-21T22:22:18.877592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0062577576409958095\n",
      "-0.04600090617207673\n",
      "0.16307040944304638\n",
      "\n",
      "-0.009055857140276746\n",
      "-0.014232296794247045\n",
      "0.15361196627922696\n",
      "\n",
      "-0.009418446809962022\n",
      "-0.027665366344261776\n",
      "0.16010932609017375\n",
      "\n",
      "-0.05502685209152669\n",
      "-0.049947435246535866\n",
      "0.1661552575352783\n",
      "\n",
      "-0.005171155783737591\n",
      "-0.039876971002700004\n",
      "0.14715201192386776\n",
      "\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for _ in range(5):\n",
    "    cv = KFold(shuffle=True)\n",
    "    cv.random_state = np.random.RandomState()\n",
    "    print(cross_val_score(baseline_reg, X, y, cv=cv).mean())\n",
    "    print(cross_val_score(linear_reg, X, y, cv=cv).mean())\n",
    "    print(cross_val_score(reg, X, y, cv=cv).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-inference",
   "language": "python",
   "name": "ml-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
